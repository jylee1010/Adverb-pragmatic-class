{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ad1a4c-ca47-4453-8bce-a30711d7db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58f8464-fc5d-4601-925d-8717482104fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.adverbs.csv\")\n",
    "data[\"sentence\"] = data.apply(lambda x: x[\"sentence\"].lower().replace(x[\"adverb\"], f\"<t>{x[\"adverb\"]}</t>\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65743470-ba81-4fdb-aea7-5a74252ae490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adverb</th>\n",
       "      <th>type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>correct</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abominably</td>\n",
       "      <td>adverb.manner</td>\n",
       "      <td>i don't know anyone who could have behaved so ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absently</td>\n",
       "      <td>adverb.manner</td>\n",
       "      <td>he read the letter &lt;t&gt;absently&lt;/t&gt;</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>adverb.degree</td>\n",
       "      <td>&lt;t&gt;absolutely&lt;/t&gt; right! fuck destiny, fate. a...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstemiously</td>\n",
       "      <td>adverb.manner</td>\n",
       "      <td>the monk lived &lt;t&gt;abstemiously&lt;/t&gt;, avoiding a...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abstractly</td>\n",
       "      <td>adverb.domain</td>\n",
       "      <td>&lt;t&gt;abstractly&lt;/t&gt;, i knew it could happen.</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         adverb           type  \\\n",
       "0    abominably  adverb.manner   \n",
       "1      absently  adverb.manner   \n",
       "2    absolutely  adverb.degree   \n",
       "3  abstemiously  adverb.manner   \n",
       "4    abstractly  adverb.domain   \n",
       "\n",
       "                                            sentence correct Unnamed: 4  \n",
       "0  i don't know anyone who could have behaved so ...     yes        NaN  \n",
       "1                 he read the letter <t>absently</t>     yes        NaN  \n",
       "2  <t>absolutely</t> right! fuck destiny, fate. a...     yes        NaN  \n",
       "3  the monk lived <t>abstemiously</t>, avoiding a...     yes        NaN  \n",
       "4         <t>abstractly</t>, i knew it could happen.     yes        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cb0da2-7cf6-4f60-a413-008b3b31d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cdcbb1f-59c1-406e-b1be-d4b51547a33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f06ec75fc3a4665894ac49f30f88178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_list = sorted(list(set(data['type'])))  # might be strings\n",
    "label2id = {l:i for i,l in enumerate(label_list)}\n",
    "id2label = {i:l for i,l in enumerate(label_list)}\n",
    "\n",
    "def map_labels(batch):\n",
    "    return {\"label\": [label2id[l] for l in batch['type']]}\n",
    "\n",
    "data = data.map(map_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ada00a63-c4a0-4d54-9711-837837079770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mroberta-base\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m      5\u001b[39m tokenizer.add_tokens([\u001b[33m\"\u001b[39m\u001b[33m<t>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m</t>\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Adverb-pragmatic-class/.venv/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Adverb-pragmatic-class/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Adverb-pragmatic-class/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:5048\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5038\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5039\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5041\u001b[39m     (\n\u001b[32m   5042\u001b[39m         model,\n\u001b[32m   5043\u001b[39m         missing_keys,\n\u001b[32m   5044\u001b[39m         unexpected_keys,\n\u001b[32m   5045\u001b[39m         mismatched_keys,\n\u001b[32m   5046\u001b[39m         offload_index,\n\u001b[32m   5047\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5048\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5054\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5059\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5063\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5064\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5065\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Adverb-pragmatic-class/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:5432\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_hqq_or_quark:\n\u001b[32m   5431\u001b[39m     expanded_device_map = expand_device_map(device_map, expected_keys)\n\u001b[32m-> \u001b[39m\u001b[32m5432\u001b[39m     \u001b[43mcaching_allocator_warmup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_device_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[38;5;66;03m# Prepare and compatabilize arguments for serial and parallel shard loading\u001b[39;00m\n\u001b[32m   5435\u001b[39m args_list = [\n\u001b[32m   5436\u001b[39m     (\n\u001b[32m   5437\u001b[39m         shard_file,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5452\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m checkpoint_files\n\u001b[32m   5453\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Adverb-pragmatic-class/.venv/lib/python3.13/site-packages/transformers/modeling_utils.py:6089\u001b[39m, in \u001b[36mcaching_allocator_warmup\u001b[39m\u001b[34m(model, expanded_device_map, hf_quantizer)\u001b[39m\n\u001b[32m   6087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device.type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mxpu\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   6088\u001b[39m     torch_accelerator_module = \u001b[38;5;28mgetattr\u001b[39m(torch, device.type)\n\u001b[32m-> \u001b[39m\u001b[32m6089\u001b[39m     index = device.index \u001b[38;5;28;01mif\u001b[39;00m device.index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtorch_accelerator_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6090\u001b[39m     device_memory = torch_accelerator_module.mem_get_info(index)[\u001b[32m0\u001b[39m]\n\u001b[32m   6091\u001b[39m     \u001b[38;5;66;03m# Allow up to (max device memory - 1.2 GiB) in resource-constrained hardware configurations. Trying to reserve more\u001b[39;00m\n\u001b[32m   6092\u001b[39m     \u001b[38;5;66;03m# than that amount might sometimes lead to unnecessary cuda/xpu OOM, if the last parameter to be loaded on the device is large,\u001b[39;00m\n\u001b[32m   6093\u001b[39m     \u001b[38;5;66;03m# and the remaining reserved memory portion is smaller than the param size -> torch will then try to fully re-allocate all\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   6096\u001b[39m     \u001b[38;5;66;03m# Note that we use an absolute value instead of device proportion here, as a 8GiB device could still allocate too much\u001b[39;00m\n\u001b[32m   6097\u001b[39m     \u001b[38;5;66;03m# if using e.g. 90% of device size, while a 140GiB device would allocate too little\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Adverb-pragmatic-class/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:1069\u001b[39m, in \u001b[36mcurrent_device\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcurrent_device\u001b[39m() -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   1068\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._cuda_getDevice()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Adverb-pragmatic-class/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:410\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    414\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_list), device_map=\"cuda\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_tokens([\"<t>\", \"</t>\"])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "model.config.label2id = label2id\n",
    "model.config.id2label = id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31863db-a1c0-42b2-9be5-c4e5cc7bb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    output = tokenizer(examples[\"sentence\"], padding=\"max_length\", max_length=64, truncation=True, return_tensors=\"pt\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc935d-ce4b-4d34-8452-3a06326dcd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(tokenize, remove_columns=[\"sentence\", \"type\", \"adverb\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244f20d-8828-45ce-9f29-1d483a3cfca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally set format to return torch tensors (so collator sees tensors)\n",
    "data.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41c9f6-2086-4e9c-aed3-d7bc44dada24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0a67b-9e02-4ca8-9087-80f83db5bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # convert the logits to their predicted class\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    accuracy = accuracy_score(predictions, labels)\n",
    "    p, r, fscore, _ = precision_recall_fscore_support(predictions, labels, average=\"weighted\", zero_division=0.0)\n",
    "    return {\n",
    "        \"acc\": accuracy,\n",
    "        \"precision\": p,\n",
    "        \"recall\": r,\n",
    "        \"fscore\": fscore,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8834f4-80dd-46ac-a715-f8f52b2673bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"adverbs_classifier\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"acc\",\n",
    "    save_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bbc786-9dbe-43ca-8d40-e78a66551761",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f07a0b-ffa1-4f02-a98b-3e1fe077c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"adverb_os_llm.csv\")\n",
    "test[\"label\"] = \"adverb.\" + test[\"jooyoung\"].str.replace(\"-\", \"_\")\n",
    "test = test[[\"sentence\", \"label\"]]\n",
    "test = test.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2ae44-a3dc-4d70-9dc9-e289224c26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset.from_pandas(test)\n",
    "test = test.map(tokenize, batched=True, remove_columns=[\"sentence\"])\n",
    "def map_labels(batch):\n",
    "    return {\"label\": [label2id[l] for l in batch['label']]}\n",
    "\n",
    "test = test.map(map_labels, batched=True)\n",
    "\n",
    "test.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb0e2f-4162-4d21-bf1c-d03da07bf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trainer.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b13464-b3d0-4dd0-838b-8112a2b8154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "trues = [id2label[x.item()] for x in test[\"label\"]]\n",
    "preds = [id2label[x] for x in pred.predictions.argmax(-1)]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(trues, preds, labels=label_list)\n",
    "\n",
    "# Plot confusion matrix\n",
    "\n",
    "plt.figure(figsize=(13,25))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_list)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix with Class Names\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401dd9f-2729-436c-ae19-c20f8809d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e813b-5e23-4346-8193-0e4274468d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ffbeb-deff-41c1-9658-3205a574f12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
